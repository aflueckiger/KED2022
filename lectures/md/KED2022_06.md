---
title: The ABC of Computational Text Analysis
subtitle: "#6 Learning Regular Expressions"
author: "Alex Flückiger"
institute: "Faculty of Humanities and Social Sciences<br>University of Lucerne" 
date: "7 April 2022"
lang: en-US
---



## Recap last Lecture

- well solved assignment #1 :confetti_ball:
  - [example solution](https://github.com/aflueckiger/KED2022/blob/master/assignments/assignment_1/flueckiger_KED2022_1_solutions.sh)
- counting words :1234:
  - particular or all words
- preprocessing ​and cleaning :soap:



::: notes

- Übung
  - Feedback alle erhalten? Fragen?
  - Bearbeitungszeit unterschiedlich (45min - 5h)
  - Google ok, aber commands erklären
  - Beispiellösungen aufgeschaltet, andere Wege möglich
  - Ordner müssen existieren, Dateien nicht um reinzuschreiben
- Frequenzanalysen
  - Übersicht gewinnen: Wo liegen Schwerpunkte?
  - vergleichbar mit Ngram-Viewer
  - gleiche Tools erlauben auch über die Zeit

:::

## Outline

- introduction regular expression :sparkles:
- practicing RegEx :roller_coaster:

::: notes

- Halbzeit von Semester, langsam gehts ans Eingemachte
- Simpler Plan, RegEx allerdings mühsam
- uralt, aber unumgänglich für Data Cleaning
- je nach Zeit, nächstes Mal nochmals RegEx + Übungszeit
  - evtl. Verschiebungen im Zeitplan

:::



# Text as Pattern

## Formal Search Patterns

### How to extract **any** email address in a text collection? 

```bash
Please contact us via info@organization.org.
---
For specific questions ask Mrs. Green (a.green@mail.com).
---
Reach out to support@me.ch
```

. . .

**Solution:** Write a single pattern to match any valid email all

```bash
[\w.-_]+@[\w-_]+\.[a-z]{2,}		# matches any valid email address
```

::: notes

- Was meint Text als Pattern?
  - am einfachsten an Problemstellung zu sehen
- Frage an Studis: Wie macht ihr das?
  - Bsp. Marketing-Analyse oder Wistleblower Korpus
- allen bekannt: Suche in Text
  - Suche nach @ findet alle Adressen
  - wie aber extrahieren und welche Teile gehören genau dazu?
- kryptisch + hässlich, aber beliebig expressive Beschreibungssprache

:::

## What are patterns for?

- finding :mag_right:
- extracting :hammer_and_wrench:
- removing/cleaning :wastebasket:
- replacing :repeat:

<br>

**... any parts in texts**

::: notes

- RegEx mit breiter Anwendung
  - für Preprocessing Textanalysen unverzichtbar
  - Data Cleaning

:::

## Data Cleaning is paramount!



![](../images/data_cleaning.png)



::: notes

- Aufbereitung braucht viel Zeit

[src](https://medium.com/koverhoop/data-cleaning-and-pre-processing-in-python-b28eea7ac045)

:::

## What is RegEx?

### RegEx = Regular Expressions = Patterns

- **literal** string of characters
  - word, phrases, dates etc.
- highly flexible **meta** expressions
  - e.g.,`\w` represents alphanumeric characters
- `[Cc]o+l` &rarr; Col, col, Cool, coool ...
- akin to regular languages



::: notes

- Regex = Muster = generalisierende Beschreibung
- Erklären von String = Zeichensequenz
- zwei Arten von Zeichen
- Literale = Zeichen steht für tatsächliches Zeichen (buchstabentreue Repräsentation)
  - wie letztes Mal
- Meta-Zeichen = Zeichen mit spezieller Bedeutung
  - anfänglich verwirrend
  - Thema heutiger Sitzung
- genaue mathematische Definition hier nicht Thema

:::

## Finding + Extracting

#### **g**lobally search for **r**egular **e**xpression and **p**rint (grep)

- tool to filter/keep certain lines only
- allow extended regex patterns
  - use `egrep` instead of  `grep`

```bash
egrep 'yes' file.txt		# search in a specific file
egrep -r 'yes' folder 		# search recursively within folder

egrep 'yes'	*.txt			# keep lines containing pattern (yes)
egrep -i 'yes' *.txt		# dito, ignore casing (Yes, yes, YES ...)
egrep -v 'noisy' *.txt		# do NOT keep lines containing noisy

# extract raw match only to allow for subsequent counting
egrep –o 'only' *.txt		# print match only, not entire line
egrep –h 'only' *.txt		# suppress file name
```



::: notes

- Empfehlung: immer egrep benutzen

:::

## Quantifiers

#### repeat preceding character `X` times

- `?` zero or one
- `+` one or more
- `*` zero or any number
- `{n}`, `{m,n}` a specified number of times

```bash
egrep -r "Bundesrath?es"		# match old and new spelling of
egrep -r "aa+" 					# match two or more "a"
egrep -r "e{2}"					# match sequence of two "e"
```



:warning: Do not confuse regex with Bash wildcards!



::: notes

- erste Klasse von Meta-Symbolen: Quantifikatoren
- definieren Anzahl von vorangehendem Zeichen
- in Regex beziehen sich Operatoren auf vorderes Zeichen, in Wildcard nicht

:::



## Character Sets

* `[...]` any of these character
  * any vowel: `[auoei]`
  * any digit: `[0-9]`
  * any letter: `[A-Za-z]`
* `[^...]` any character but none of these
  * anything but the vowels: `[^auoei]`



```bash
# match the capitalized and non-capitalized form
egrep -r '[Gg]rüne'

# match sequences of 3 vowels
egrep -r [aeiou]{3}

# extract all bigrams (sequence of two words)
egrep -rohi '[a-z]+ [a-z]+'
```



## Special Symbols

* `.` any character (excl. newline)
* `\` escaping to match literal 
  * `\.` means the literal `.` instead of "any symbol"
* `\w` any alpha-numeric character
  * same as `[A-Za-z0-9_]`
* `\s` any whitespace (space, newline, tab)
  * same as `[ \t\n]`



```bash
# match anything between brackets
egrep -r '\(.*\)'
```

::: notes

- Klammern sind auch Metasymbole

:::

## The power of `.*` ...{data-background=#4d7e65} 

matches ***any character*** ***any times***



## More complex Examples

```bash
# extract basename of URLs
egrep -ro "www\.[\w-_]+\.[a-z]{2,}"

# extract valid email adresses
egrep -ro "[\w.-_]+@[\w-_]+\.[a-z]{2,}" */*.txt
```

::: notes

- bei Erstellung von Online-Accounts prüfen RegEx Validität von Email

:::

## Combining RegEx with Frequency Analysis

### something actually useful

```bash
# count political areas by looking up words ending with "politik"
egrep -rioh '\w*politik' */*.txt | sort | uniq -c | sort -h

# count ideologies/concepts by looking up words ending with "ismus"
egrep -rioh '\w*ismus' */*.txt | sort | uniq -c | sort -h
```



::: notes

- bis jetzt Spielerei, um RegEx zu lernen
- Eingehen auf Resourcen am Ende von Präsentation

:::

## Start simple, <br>add complexity subsequently. {data-background=../images/knitting.jpg}

<!-- https://wallpaperscraft.com/download/needles_thread_knitting_105073/2048x1365 -->



## Replacing + Removing

### **s**tream **ed**itor (sed)

- advanced find + replace using regex
  - `sed "s/WHAT/WITH/g" file.txt`
-  `sed` replaces any sequence,  `tr` only single symbols



```bash
echo "hello" | sed "s/llo/y/g"		# replace "llo" with a "y"

# by setting the g flag in "s/llo/y/g",
# sed replaces all occurences, not only the first one
```



::: notes

- egrep für Extraktion, sed für Manipulation
  - wichtig um Daten aufzubereiten
- wie Funktion von Word, nur mächtiger dank Regex
- Löschen = Ersetzen mit leeren Sequenz
- flag "global"
- Demonstration mit \b
- echo `"hello hell" | sed "s/l\b/y/g"`

:::



## Contextual Replacing 

#### reuse match with grouping

* define a group with parentheses `(group_pattern)`
* `\1`  equals the expression inside first pair of parentheses
* `\2`  expression of second pair
* ...



```bash
# swap order of name (last first -> first last)
echo "Lastname Firstname" | sed -E "s/(.*) (.*)/\2 \1/"

# matching also supports grouping
# match any pair of digits (two identical digits)
egrep -r "([0-9])\1([0-9])\2"
```



::: notes

- Teilausdruck gruppieren zur Wiederverwendung
- Klammern 
  - ebenfalls Metazeichen

:::



## More Meta-Symbols

* `\b` word boundary

  * `word\b` does not match `words`

* `^` begin of line and `$` end of line

  * `^A` matches only `A` at line start

* `|` disjunction (OR)
  * `(Mr|Mrs|Mr\.|Mrs\.) Green` matches alternatives 




::: notes

- diese Symbole sind leer, sie matchen keine Zeichen
- spezifizieren Positon von regulärem Ausdruck
- line start hilfreich für übung

:::



## Greediness Trap

- greedy ~ match the longest string possible
- quantifiers `*` or `+` are greedy
- non-greedy by excluding some symbols
  -  `[^EXCLUDE_SYMBOLS]` instead of `.*`

```bash
# greedy: an apple, other apple
echo 'an apple, other apple' | egrep 'a.*apple'

# non-greedy: an apple
echo 'an apple, other apple' | egrep 'a[^,]*apple'
```

::: notes

- `. ` = jegliche Zeichen, beliebige Länge

:::

## Assignment #2 :writing_hand:

- get/submit via OLAT
  - starting tomorrow
  - deadline 9 April 2022, 23:59
- use forum on [OLAT](https://lms.uzh.ch/auth/RepositoryEntry/16703095856)
  - subscribe to get notifications
- ask friends for support, not solutions


::: notes

- neue Deadline

:::

## In-class: Game {data-background=#3c70b5}

1. Make sure that your local copy of the Github repository KED2022 is up-to-date with `git pull`.  Go to the party programmes in `materials/party_programmes/txt`.
2. Use `egrep` to extract all uppercased words like `UNO, OECD, SP` and count their frequency.
3. Send me a private chat message with the most frequent abbreviation from 2).



```bash
# Some not so random hints 
piping with |
sort
uniq -c
egrep -roh */*.txt
```

::: notes

- `egrep -roh '[A-Z]{2,}' */*.txt | sort | uniq -c | sort -h `

:::

## In-class: Exercises I{data-background=#3c70b5}

1. Update your local copy of the GitHub repository KED2022 with `git pull`.  Go to the party programmes in `KED2022/materials/data/swiss_party_programmes/txt`.

2. Use `egrep` to extract all uppercased words that are abbreviations in most cases (e.g., UNO, SVP, SP).

3. Use `egrep` to extract words following any of these strings: `der die das`.

4. Do the self-check on the next slide.

5. Use `sed -E` to remove the table of content, the footer and the page number in the programme of the Green Party. Check the corresponding PDF to get a visual impression and test your regular expression with `egrep` first to see if you match the correct parts in the document.

   


## In-class: Self-Check{data-background=#3c70b5}

#### equivalent patterns

```bash
a+ == aa* 				# "a" once or more than once
a? == (a|_) 			# "a" once or nothing
a{3} == aaa				# three "a"
a{2,3} == (aa|aaa)		# two or three "a"
[ab] == (a|b)			# "a" or "b"
[0-9] == (0|1|2|3|4|5|6|7|8|9)	#any digit
```

## In-class: Exercise II{data-background=#3c70b5}

1. Since you know about RegEx, we can use a more sophisticated tokenizer to split a text into words. What  is the difference between the old and new approach?  Test it and check the helper page with `man`.

   ```bash
   # new, improved approach
   cat text.txt | tr -sc "[a-zäöüA-ZÄÖÜ0-9-]" "\n"
   
   # old approach
   cat text.txt | tr ' ' '\n'	
   ```

## In-class: Exercise III{data-background=#3c70b5}

1. Count all the bigrams (sequence of two words) using character sets and quantifiers. What about trigrams (three words)?
2. Extract the words following numbers (also consider numbers like: `1'000, 1,000 or 5%`). Then, count all the words while excluding the numbers themselves. Hint: Pipe another grep to remove the digits.
3. You are ready to come up with your own patterns...



::: notes

- number task
  - `egrep -rho "[0-9',%] \w+" | egrep -hoi '[a-z]+' | sort | uniq -c | sort -h`

:::

## More Resources

#### required

- Ben Schmidt. 2019. Regular Expressions. [online](https://github.com/HumanitiesDataAnalysis/HDA19/blob/master/Handouts/01-regex.pdf)



#### highly recommended

- Nikolaj Lindberg. egrep for Linguists. [online](https://stts.se/egrep_for_linguists/egrep_for_linguists.pdf)

## Have a nice <br>Easter break! {data-background=../images/easter-eggs.jpg}