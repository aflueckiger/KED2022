{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VORGEHEN: \n",
    "\n",
    "1) Module importieren\n",
    "2) Define Function\n",
    "3) Create Corpus\n",
    "4) Create Subcorpus (beide Geschlechter, nach 2000)\n",
    "5) Subcorpus als csv abspeichern\n",
    "6) csv mit scattertext importieren\n",
    "7) die beiden Achsen aufspannen auf Basis der Variable Geschlecht (m/f)\n",
    "\n",
    "(Wenn alle Spaltennamnen stimmen sollte es so klappen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1) Import modules\n",
    "\n",
    "import spacy\n",
    "import textacy\n",
    "import scattertext as st\n",
    "import pandas as pd\n",
    "import plotnine as p9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2) Define function\n",
    "\n",
    "def get_texts_from_csv(f_csv, text_column):\n",
    "    \"\"\"\n",
    "   Read dataset from a csv file and sequentially stream the rows,\n",
    "    including metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    # read dataframe\n",
    "    df = pd.read_csv(f_csv)\n",
    "\n",
    "    # keep only documents that have text\n",
    "    filtered_df = df[df[text_column].notnull()]\n",
    "    \n",
    "    # iterate over rows in dataframe\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        \n",
    "        #read text and join lines (hard line-breaks)\n",
    "        text = row[text_column].replace('\\n', ' ')\n",
    "\n",
    "        #use all columns as metadata, except the column with the actual text\n",
    "        metadata = row.to_dict()\n",
    "        del metadata[text_column]\n",
    "\n",
    "        # return documents one after another (sequentially)\n",
    "        yield (text, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3) Create Corpus\n",
    "\n",
    "# stream texts from a given folder\n",
    "f_csv = '../KED2022/materials/data/dataset_speeches_federal_council_2019.csv'\n",
    "texts = get_texts_from_csv(f_csv, text_column='text')\n",
    "\n",
    "# load german language model\n",
    "de = textacy.load_spacy_lang(\"de_core_news_sm\")\n",
    "\n",
    "# create corpus from processed documents\n",
    "corpus_speeches_XY = textacy.Corpus(de, data=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 4) Create Subcorpus (both genders, DE, after the year 2000)\n",
    "\n",
    "## subcor (filtering by meta attributes \"language\" and \"after 2000\")\n",
    "\n",
    "# function to filter by metadata \n",
    "def filter_func_1(doc):\n",
    "    return doc._.meta.get(\"Jahr\") > 2000\n",
    "\n",
    "# create new corpus after applying filter function\n",
    "subcor = textacy.corpus.Corpus(de, data=corpus_speeches_XY.get(filter_func_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 5) Export corpus as csv dataset\n",
    "\n",
    "# merge metadata and actual content for each document in the corpus\n",
    "# ugly, verbose syntax to merge two dictionaries\n",
    "data = [{**doc._.meta, **{'text': doc.text}} for doc in subcor]\n",
    "\n",
    "# export corpus as csv\n",
    "f_csv = '../KED2022/materials/data/dataset_speeches.csv'\n",
    "textacy.io.csv.write_csv(data, f_csv, fieldnames=data[0].keys())\n",
    "\n",
    "# csv format is the best to load in scattertext\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 6) Import csv to use in scattertext: load file\n",
    "\n",
    "# read dataset from csv file\n",
    "f_csv = '../KED2022/materials/data/dataset_speeches.csv'\n",
    "df = pd.read_csv(f_csv)\n",
    "\n",
    "# filter out non-german texts or very short texts\n",
    "df_sub = df[(df['Sprache'] == 'de') & (df['text'].str.len() > 10)]\n",
    "\n",
    "# make new column containing all relevant metadata (showing in plot later on)\n",
    "df_sub['descripton'] = df_sub[['Redner', 'Partei', 'Jahr']].astype(str).agg(', '.join, axis=1)\n",
    "\n",
    "# sneak peek of dataset\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 7) create scattertext plot, axes basing on the variable \"gender\"\n",
    "\n",
    "censor_tags = set(['CARD']) # tags to ignore in corpus, e.g. numbers\n",
    "\n",
    "# stop words to ignore in corpus\n",
    "de_stopwords = spacy.lang.de.stop_words.STOP_WORDS # default stop words\n",
    "custom_stopwords = set(['[', ']', '%', '*', 'â€¢', '2.', '19.', '21.', '9.', '3.'])\n",
    "de_stopwords = de_stopwords.union(custom_stopwords) # extend with custom stop words\n",
    "\n",
    "# create corpus from dataframe\n",
    "# lowercased terms, no stopwords, no numbers\n",
    "# use lemmas for English only, German quality is too bad\n",
    "corpus_speeches = st.CorpusFromPandas(df_sub, # dataset\n",
    "                             category_col='Geschlecht', # index differences by ...\n",
    "                             text_col='text', \n",
    "                             nlp=de, # German model\n",
    "                             feats_from_spacy_doc=st.FeatsFromSpacyDoc(tag_types_to_censor=censor_tags, use_lemmas=False),\n",
    "                             ).build().get_stoplisted_unigram_corpus(de_stopwords)\n",
    "# produce visualization (interactive html)\n",
    "html = st.produce_scattertext_explorer(corpus_speeches,\n",
    "            category='m', # set attribute to divide corpus into two parts\n",
    "            category_name='male',\n",
    "            not_category_name='female',\n",
    "            metadata=df_sub['descripton'],\n",
    "            width_in_pixels=1000,\n",
    "            minimum_term_frequency=5, # drop terms occurring less than 5 times\n",
    "            save_svg_button=True,                          \n",
    ")\n",
    "\n",
    "# write visualization to html file\n",
    "fname = '..KED2022/materials/data/gender_differences_final.html'\n",
    "open(fname, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "About the scattertext - Explanation for Orientation:\n",
    "\n",
    "Terms in upper right    = frequently used by male and female speakers alike\n",
    "Terms in lower right    = often used by female speakers\n",
    "Terms in upper left     = often used by male speakers\n",
    "Terms in lower left     = infrequently used by male and female speakers alike\n",
    "\n",
    "### What can we see?\n",
    "\n",
    "Top 3 terms in male speeches:       Geschichte, Zusammenhalt, Tessin  \n",
    "Top 3 terms in female speeches:     gemeinsam, Grenzen, brauchen\n",
    "\n",
    "Top 3 terms in both genders:        Menschen, Land, Schweiz\n",
    "\n",
    "### Important to keep in mind\n",
    "\n",
    "Document count total:   96\n",
    "male document count:    67\n",
    "female document count:  29"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
